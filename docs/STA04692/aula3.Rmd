---
title: "STA13824 - Análise de regressão"
subtitle: "Interpretação geométrica do estimador MQO"
author: "Fabio A. Fajardo Molinares"
institute: "LECON/DEST - UFES"
date: "Vitória. ES - `r format(Sys.Date(), format='%d/%m/%Y')`"
output:
  xaringan::moon_reader:
    includes:
      after_body: insert-logo.html
    css: [xaringan-themer.css, "https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css"]
    lib_dir: libs
    nature:
      ratio: '16:9' 
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: animated, fadeIn
```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer); library(dplyr); library("DT"); library(plotly) #library(icons)
style_mono_light(base_color = "#23395b")
```
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```
```{r, load_refs, include=FALSE, cache=FALSE}
library("RefManageR"); library("bibtex")
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("ref_ementa.bib", check = FALSE)
```

<style> body {text-align: justify} </style> <!-- Justify text. -->


### Alguns resultados da álgebra linear - I
**Produto interno**: Sejam $\mathbf{x}$, $\mathbf{y}$ e $\mathbf{z}$ três vetores 
de um espaço vetorial $V$, definido no plano complexo $\mathbb{C}$. Seja $\lambda$ 
um escalar. Define-se o produto interno como uma função 
$\langle\cdot, \cdot\rangle:V\times V \longrightarrow \mathbb{C}$, tal que
1. $\langle\mathbf{x}, \mathbf{y}\rangle=\overline{\langle\mathbf{y}, \mathbf{x}\rangle}\quad$  (*Simetria Hermitiana*);
1. $\langle\mathbf{x}+\mathbf{y}, \mathbf{z}\rangle=\langle\mathbf{x}, \mathbf{z}\rangle+\langle\mathbf{y}, \mathbf{z}\rangle\quad$ (*Distributividade*);
1. $\langle\lambda\mathbf{x}, \mathbf{y}\rangle=\lambda\langle\mathbf{x}, \mathbf{y}\rangle\quad$ (*Homogeneidade* );
1. $\langle\mathbf{x}, \mathbf{x}\rangle\ge0$. A igualdade é 
satisfeita see $\mathbf{x}$ é o vetor nulo.

> No espaço euclideano, o Item 1. é dado por
$$\langle\mathbf{x}, \mathbf{y}\rangle=\langle\mathbf{y}, \mathbf{x}\rangle=\sum_{i=1}^nx_iy_i,$$
onde $\mathbf{x}=(x_1,x_2,\ldots,x_n)'$ e $\mathbf{y}=(y_1,y_2,\ldots,y_n)'$.

---
class: animated, slideInRight

### Alguns resultados da álgebra linear - II

* **Magnitude de um vetor**: Seja $\mathbf{x}$ um vetor. A magnitude (ou *norma*) 
de $\mathbf{x}$ define-se como

$$\lVert\mathbf{x}\rVert=\sqrt{\langle\mathbf{x}, \mathbf{x}\rangle}=\sqrt{\mathbf{x}'\mathbf{x}}= \sqrt{\sum_{i=1}^nx_i^2}.$$
* **propriedades**: Sejam $\mathbf{x}$ e $\mathbf{y}$ dois vetores de um espaço 
vetorial $V$ e $\lambda$ um escalar, então

  - $\lVert\mathbf{x}\rVert\ge0$, $\lVert\mathbf{x}\rVert=0$ see $\mathbf{x}=\mathbf{0}$;
  - $\lVert\lambda\mathbf{x}\rVert=\lambda\lVert\mathbf{x}\rVert$ ;
  - $\lVert\mathbf{x}+\mathbf{y}\rVert\le\lVert\mathbf{x}\rVert+\lVert\mathbf{y}\rVert$ (*Desigualdade triangular*).

* **Ângulo entre vetores**: Sejam $\mathbf{x}$ e $\mathbf{y}$ dois vectores de 
um espaço vectorial com produto interno, então

$$\cos\theta=\frac{\langle\mathbf{x},\mathbf{y}\rangle}{\lVert\mathbf{x}\rVert\lVert\mathbf{y}\rVert}.$$
> Em particular, dizemos que $\mathbf{x}$ e $\mathbf{y}$ são *ortogonais* see
$\langle\mathbf{x},\mathbf{y}\rangle=0$ ou, equivalentemente, $\theta=\frac\pi2$.

---
class: animated, slideInRight

### Alguns resultados da álgebra linear - III

* **Desigualdade de Cauchy-Schwarz**: A desigualdade garante que, para quaisquer 
dois vectores $\mathbf{x}$ e $\mathbf{y}$ de um espaço vectorial com produto 
interno, se tem 
$$\left|\langle\mathbf{x},\mathbf{y}\rangle\right|\le \lVert\mathbf{x}\rVert\lVert\mathbf{y}\rVert.$$

> Tem-se a igualdade, i.e., $\left|\langle\mathbf{x},\mathbf{y}\rangle\right|=\lVert\mathbf{x}\rVert\lVert\mathbf{y}\rVert\,$, see $\,\mathbf{x}=\frac{\langle\mathbf{x},\mathbf{y}\rangle}{\langle\mathbf{y},\mathbf{y}\rangle}\mathbf{y}$. 

* **Lei do paralelogramo**: A lei garante que, para quaisquer 
dois vectores $\mathbf{x}$ e $\mathbf{y}$ de um espaço vectorial com produto 
interno, se tem
$$\lVert\mathbf{x}+\mathbf{y}\rVert^2+\lVert\mathbf{x}-\mathbf{y}\rVert^2=2\lVert\mathbf{x}\rVert^2+2\lVert\mathbf{y}\rVert^2.$$

> Se $\mathbf{x}$ e $\mathbf{y}$ são ortogonais, i.e., $\langle\mathbf{x},\mathbf{y}\rangle=0$, então
$$\lVert\mathbf{x}+\mathbf{y}\rVert^2+\lVert\mathbf{x}-\mathbf{y}\rVert^2=\lVert\mathbf{x}\rVert^2+\lVert\mathbf{y}\rVert^2.$$


Para detalhes ver, por exemplo, o Apêndice A do livro de `r Citet(myBib, "greene2003")`,
disponível [<ins>aqui</ins>](https://bit.ly/3j5fJOk).

<font size="2">Adicionalmente, sugere-se a revisão do `r Citet(myBib, "searle2017")` 
e `r Citet(myBib, "magnus2019")`.
</font>

---
class: animated, bounceInDown

### Mínimos quadrados ordinários (MQO)

Considere o modelo é linear, dado por

$$Y=\mathbf{X\,\beta}+\mathbf{\epsilon}.$$

O método MQO tem como objetivo encontrar 
$\widehat{\mathbf{\beta}}=\underset{\mathbf{\beta}\,\in\,\Theta}{\arg\min}\, S(\mathbf{\beta})$,
onde 
$$
S(\mathbf{\beta})=\mathbf{\epsilon}'\mathbf{\epsilon}=(Y-\mathbf{X\,\beta})'(Y-\mathbf{X\,\beta}).
$$
Pelas Suposições **A1.** e **A2.**, o estimador de MQO para $\mathbf{\beta}$ é 
dado por

$$\mathbf{\widehat{\beta}}=\left(\mathbf{X}'\mathbf{X}\right)^{-1}\mathbf{X}'Y.$$
> Pelas Suposições **A1-A3**, o estimador MQO é não-viesado para $\mathbf{\beta}$, i.e.,
$\mathbb{E}\left[\widehat{\mathbf{\beta}}\,\big|\,\mathbf{X}\right]=\mathbf{\beta}.$

> Pelas Suposições **A1-A4**, $\textrm{cov}\left[\widehat{\beta}\,\big|\,\mathbf{X}\right]=\sigma^2\left(\mathbf{X}'\mathbf{X}\right)^{-1}$.


---
class: animated, bounceInDown

### Mínimos quadrados ordinários (MQO)

```{r, out.width='60%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/MQO_mod1.png")
```


---
class: inverse, hide-logo, middle, center

# Equações normais

---
class: animated, slideInRight

### Equações normais - I
O sistema de **equações normais** é dado por
$$
\mathbf{X}'\mathbf{X\widehat{\beta}}=\mathbf{X}'Y.
$$
#### Algumas considerações
* Seja $\widehat{Y}=\mathbf{X\widehat{\beta}}$ o *vetor  ajustado* associado ao
vetor $Y$. Observe-se que

$$\widehat{Y}=\mathbf{X\widehat{\beta}}=\mathbf{X}\left(\mathbf{X}'\mathbf{X}\right)^{-1}\mathbf{X}'Y=\mathbf{H}Y.$$
A matriz $\mathbf{H}=\mathbf{X}\left(\mathbf{X}'\mathbf{X}\right)^{-1}\mathbf{X}'$
é de dimensão $n\times n$ e será chamada **matriz "_hat_"** (*matriz chapéu*, 
na tradução livre).

> A matriz "_hat_", também chamada de *matriz de projeção*, será de grande 
relevância na análise de regressão.

---
class: animated, slideInRight

### Equações normais - I

```{r, out.width='60%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/MQO_mod2.png")
```

---
class: animated, fadeIn

### Equações normais - I

```{r, out.width='60%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/MQO_mod4.png")
```

---
class: animated, fadeIn

### Equações normais - I

```{r, out.width='60%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/MQO_mod3.png")
```

---
class: animated, fadeIn

### Equações normais - I

```{r, out.width='60%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/MQO_mod5.png")
```

---
class: animated, slideInRight

### Equações normais - I

#### Algumas propriedades da matriz $\textbf{H}$

A matriz "_hat_", dada por
$$\mathbf{H}=\mathbf{X}\left(\mathbf{X}'\mathbf{X}\right)^{-1}\mathbf{X}'$$
é a matriz de projeção ortogonal no espaço coluna da matriz $\mathbf{X}$. A
matriz $\textbf{H}$ satisfaz as seguintes propriedades

1. $\mathbf{X}'\left(Y-\mathbf{X\widehat{\beta}}\right)=\mathbf{X}'\left(Y-\mathbf{H}Y\right)=\mathbf{0}$. 
Em outras palavras, $(\mathbf{I}-\mathbf{H})Y$ e $\mathbf{X}$ são ortogonais;

1. $\mathbf{H}$ é simétrica (assim como $\mathbf{I}-\mathbf{H}$);

1. $\mathbf{H}$ é idempotente, i.e., $\mathbf{H}^2=\mathbf{H}$ (assim como $\mathbf{I}-\mathbf{H}$);

1. $\mathbf{X}$ é invariante sob $\mathbf{H}$, i.e., $\mathbf{HX}=\mathbf{X}$, então
$\left(\mathbf{I}-\mathbf{H}\right)\mathbf{X}=\mathbf{0}$;

1. $\left(\mathbf{I}-\mathbf{H}\right)\mathbf{H}=\mathbf{H}\left(\mathbf{I}-\mathbf{H}\right)=\mathbf{0}$.


---
class: animated, slideInRight

### Equações normais - II

* A diferença entre os vetores observado e ajustado é chamado de *vetor residual*
ou *vetor de resíduos*, i.e., $e = Y-\widehat{Y}$. Em termos da matriz "_hat_",
o vetor de resíduos pode ser escrito como

$$e=Y-\widehat{Y}=Y-\mathbf{X\widehat{\beta}}=Y-\mathbf{H}Y=(\mathbf{I}-\mathbf{H})Y;$$
* O vetor $Y$ pode ser representado como a soma de duas componentes **ortogonais**, 
uma componente de projeção (*ajustado*) e uma componente residual, i.e.,

$$Y=\mathbf{H}Y+\left(\mathbf{I}-\mathbf{H}\right)Y.$$
Dessa forma, usando o teorema de Pitágoras, $$Y'Y=Y'\mathbf{H}'\mathbf{H}Y+Y'\left(\mathbf{I}-\mathbf{H}\right)'\left(\mathbf{I}-\mathbf{H}\right)Y=\widehat{Y}'\widehat{Y}+e'e$$
ou

$$\lVert Y\rVert^2=\lVert\widehat{Y}\rVert^2+\lVert e\rVert^2=\lVert\widehat{Y}\rVert^2+\lVert Y-\widehat{Y}\rVert^2.$$

---
class: animated, slideInRight

### Equações normais - II

```{r, out.width='60%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/MQO_mod3.png")
```


---
background-image: url("images/regression-geometry2.png")
background-size: contain

class: fadeIn
### Equações normais - II


---
class: animated, lightSpeedIn
# Referências

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(myBib, .opts = list(check.entries = FALSE))
```

---
class: animated, hide-logo, bounceInDown
## Política de proteção aos direitos autorais

> <span style="color:grey">O conteúdo disponível consiste em material protegido pela legislação brasileira, sendo certo que, por ser
o detentor dos direitos sobre o conteúdo disponível na plataforma, o **LECON** e o **NEAEST** detém direito
exclusivo de usar, fruir e dispor de sua obra, conforme Artigo 5<sup>o</sup>, inciso XXVII, da Constituição Federal
e os Artigos 7<sup>o</sup> e 28<sup>o</sup>, da Lei 9.610/98.
A divulgação e/ou veiculação do conteúdo em sites diferentes à plataforma e sem a devida autorização do
**LECON** e o **NEAEST**, pode configurar violação de direito autoral, nos termos da Lei 9.610/98, inclusive podendo
caracterizar conduta criminosa, conforme Artigo 184<sup>o</sup>, §1<sup>o</sup> a 3<sup>o</sup>, do Código Penal.
É considerada como contrafação a reprodução não autorizada, integral ou parcial, de todo e qualquer
conteúdo disponível na plataforma.</span>

.pull-left[
```{r, out.width='50%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/logo_lecon.png")
```
]
.pull-right[
```{r, out.width='50%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/logo_neaest.png")
```
]
<br></br>
.center[
[https://lecon.ufes.br](https://lecon.ufes.br/) &emsp; &emsp;  &emsp; &emsp; [https://analytics.ufes.br](https://analytics.ufes.br)
]

<font size="2"><span style="color:grey">Material elaborado pela equipe LECON/NEAEST: 
Alessandro J. Q. Sarnaglia, Bartolomeu Zamprogno, Fabio A. Fajardo, Luciana G. de Godoi 
e Nátaly A. Jiménez.</span></font>
