---
title: "STA13824 - Análise de regressão"
subtitle: "Detecção de dados atípicos"
author: "<br/><br/>"
institute: "LECON/DEST - UFES"
date: "Vitória, ES. - `r format(Sys.Date(), format='%d/%m/%Y')`"
output:
  xaringan::moon_reader:
    includes:
      after_body: ["insert-logo.html"]
    css: [xaringan-themer.css, "https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css"]
    lib_dir: libs
    nature:
      ratio: '16:9' 
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class: animated, fadeIn
```{r xaringan-themer, include=FALSE, warning=FALSE}
library("xaringanthemer"); library("dplyr"); library("DT"); library("plotly")
style_mono_light(base_color = "#23395b")
```
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```
```{r, load_refs, include=FALSE, cache=FALSE}
library("RefManageR"); library("bibtex")
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("ref_ementa.bib", check = FALSE)
```

<style> body {text-align: justify} </style> <!-- Justify text. -->

### Dados atípicos (_outliers_) - I

#### Algumas considerações

* Geralmente, a principal razão de identificar dados atípicos é a necessidade 
de utilizar-se um método adequado para lidar com tais observações. As mesmas
afetam todas as inferências do ajuste.

* Para lidar com observações atípicas, podemos considerar dois cenários: 
  - **Simples identificação**: A identificação de tais observações pode levar a 
  sua rejeição, sua incorporação através da revisão do modelo ou método de 
  estimação, ou verificação de deficiências no conjunto de dados e necessidade 
  de novos experimentos;
  
  - **Simples acomodação**: Nesse cenário o objetivo é acomodar tais observações
  no conjunto de dados por meio de modificações apropriadas no modelo ou método 
  de análise adequado, sem a necessidade de identificar as observações 
  discrepantes de antemão.

<br></br>

Para detalhes `r Citet(myBib, "greene:2007")`, 
`r Citet(myBib, "maronna:2019")`, `r Citet(myBib, "rao:2001")`,
`r Citet(myBib, "rousseeuw:leroy:1987")`,
`r Citet(myBib, "cook:weisberg:1982")`.

---
class: animated, slideInRight

### Dados atípicos (_outliers_) - II

Na análise de regressão linear há três tipos de dados influentes:

1. **Outlier**: Quando a observação é influente somente na direção da **variável resposta**;

1. **Ponto de alavancagem bom**: Quando a observação é influente apenas na direção 
do espaço das **covariáveis**. Sua presença pode ajudar a diminuir a variabilidade 
das estimativas;

1. **Ponto de alavancagem ruim**: Quando a observação é influente tanto na direção 
  da **variável resposta** quanto na direção do espaço das **covariáveis**. Sua 
  presença fará com que o hiperplano ajustado seja atraido na sua direção;


> Independente do tipo de dado influente, pelo fato de influenciarem nas 
estimativas dos parâmetros, das somas de quadrados e testes de significância,
torna-se importante avaliar uma maneira de detectá-los.

As medidas de influência estudadas na aula de [Análise residual](https://bit.ly/3jss8dU)
são bastante úteis para detectar esse tipo de pontos.


---
class: animated, slideInRight

### Dados atípicos (_outliers_) - III

.pull-left[
```{r, echo=FALSE,fig.align='right',message=FALSE,warning=FALSE}
suppressMessages(if(!require(car)) install.packages("car", repos = "http://cran.us.r-project.org"))

cars1 <- cars[1:30, ] # dados originais
cars_outliers <- data.frame(speed=c(19,19,20,20,20), dist=c(190, 186, 210, 220, 218))  # outliers.
cars2 <- rbind(cars1, cars_outliers)  # dados com outliers.

fit2 <- lm(dist ~ speed, data = cars2)
fit <- update(fit2, subset=-c(31:35))

plotly::plot_ly(cars1,x=~speed,y=~dist,type="scatter", main="sss")%>%
  add_trace(x = ~speed, y = fitted(fit), type = "scatter", mode = "line",
              line = list(width = 1, color="red"))%>%
  layout(title = 'Sem outliers',
         xaxis = list(range = c(0, 22),title="Velocidade"),
         yaxis=list(range = c(0, 220),title="Distância"),
         autosize = FALSE, width = 400, height = 400,
         margin=list(l = 50,
                     r = 50,
                     b = 100,
                     t = 100,
                     pad = 4),
         showlegend = FALSE
         )
```
]

.pull-right[
```{r, echo=FALSE,fig.align='right',message=FALSE,warning=FALSE}


plotly::plot_ly(cars2,x=~speed,y=~dist,type="scatter")%>%
  add_trace(x = ~speed, y = fitted(fit2), type = "scatter", mode = "line",
              line = list(width = 1, color="blue"))%>%
  layout(title = 'Com outliers',
         xaxis = list(range = c(0, 22),title="Velocidade"),
         yaxis=list(title="Distância"),
         autosize = FALSE, width = 400, height = 400,
         margin=list(l = 50,
                     r = 50,
                     b = 100,
                     t = 100,
                     pad = 4),
         showlegend = FALSE
         )
```
]


---
class: animated, slideInRight

### Modelo de desvio médio atípico (mean-shift outlier model) - I

Considere o seguinte modelo
$$Y=\mathbf{X}\beta+\gamma\,\delta_i+\epsilon,$$
onde $\delta_i$ é um vetor unitário, cujo $i$-ésimo elemento é igual a $1$ e os
outros elementos são $0$ e $\gamma$ o tamanho do desvio.

No modelo, a $i$-esima observação apresenta o efeito do desvio no intercepto, i.e.
$$\mathbb{E}\left[Y_i\right]=\mathbf{x}_i'\beta+\gamma.$$
O objetivo é avaliar se a mudança na $i$-ésima observação pode ser considerada
dado atípico.

Considere as seguintes hipótesis 

$$H_0: \gamma=0\quad \text{ou}\quad \mathbb{E}[Y]=\mathbf{X}\beta$$
contra

$$H_1: \gamma\ne0\quad \text{ou}\quad \mathbb{E}[Y]=\mathbf{X}\beta+\gamma\,\delta_i.$$
---
class: animated, slideInRight

### Modelo de desvio médio atípico (mean-shift outlier model) - II

A estatística de teste é dada por

$$F_i=\frac{SQ_{Res}(H_0)-SQ_{Res}(H_1)}{SQ_{Res}(H_1)/(n-p-1)}.$$
Observe que

<div class="math">
\[
  \begin{aligned}
    SQ_{Res}(H_0)&=Y'(I-H)Y=(n-p)s^2.
  \end{aligned}
\]
</div>

Por outra parte,

<div class="math">
\[
  \begin{aligned}
    SQ_{Res}(H_1)&=(n-p-1)s_{(i)}^2=Y_{(i)}'(I-H_{(i)})Y_{(i)}=Y'\left(I-H-\frac{(I-H)\delta_i\delta_i'(I-H)}{\delta_i'(I-H)\delta_i}\right)Y\\
    &=(n-p)s^2-\frac{e_i^2}{1-h_{ii}}=SQ_{Res}(H_0)-\frac{e_i^2}{1-h_{ii}}=(n-p-1)s_{(i)}^2.
  \end{aligned}
\]
</div>

O último resultado foi apresentado na aula [Análise residual - I](https://ffajardo64.github.io/statistical_learning/STA13824/aula9.html#6).

---
class: animated, slideInRight

### Modelo de desvio médio atípico (mean-shift outlier model) - II

Dessa forma,

$$F_i=\frac{SQ_{Res}(H_0)-SQ_{Res}(H_1)}{SQ_{Res}(H_1)/(n-p-1)}=\frac{e_i^2}{(1-h_{ii})s_{(i)}^2}=(r_i^*)^2,$$
onde $r_i^*$ é o $i$-ésimo resíduo estudentizado externamente. Sob $H_0$, a
estatística $F_i=(r_i^*)^2$ segue uma distribuição $F_{1,n-p-1}$.


---
class: inverse, hide-logo, middle, center

# Regressão robusta


---
class: animated, fadeIn

### Dados atípicos (_outliers_) - IV

.pull-left[
```{r, echo=FALSE,fig.align='right',message=FALSE,warning=FALSE}
plotly::plot_ly(cars1,x=~speed,y=~dist,type="scatter", main="sss")%>%
  add_trace(x = ~speed, y = fitted(fit), type = "scatter", mode = "line",
              line = list(width = 1, color="red"))%>%
  layout(title = 'Sem outliers',
         xaxis = list(range = c(0, 22),title="Velocidade"),
         yaxis=list(range = c(0, 220),title="Distância"),
         autosize = FALSE, width = 400, height = 400,
         margin=list(l = 50,
                     r = 50,
                     b = 100,
                     t = 100,
                     pad = 4),
         showlegend = FALSE
         )
```
]

.pull-right[
```{r, echo=FALSE,fig.align='right',message=FALSE,warning=FALSE}
cars_outliers <- data.frame(speed=c(19,19,20,20,20), dist=c(190, 186, 210, 220, 218))  # outliers.
cars2 <- rbind(cars1, cars_outliers)  # dados com outliers.

fit <- MASS::rlm(dist ~ speed, data = cars2)
plotly::plot_ly(cars2,x=~speed,y=~dist,type="scatter", main="sss")%>%
  add_trace(x = ~speed, y = fitted(fit2), type = "scatter", mode = "line",
              line = list(width = 1, color="blue"))%>%
  add_trace(x = ~speed, y = fitted(fit), type = "scatter", mode = "line",
              line = list(width = 1, color="red"))%>%
  layout(title = 'Com outliers',
         xaxis = list(range = c(0, 22),title="Velocidade"),
         yaxis=list(title="Distância"),
         autosize = FALSE, width = 400, height = 400,
         margin=list(l = 50,
                     r = 50,
                     b = 100,
                     t = 100,
                     pad = 4),
         showlegend = FALSE
         )
```
]


---
class: animated, slideInRight

### M - Estimadores

Podem-se considerar duas formas de de M-estimadores:

* **Forma simples**: $$\min_{\beta}\sum_{i=1}^n\rho\left(Y_i-\mathbf{x}_i'\beta\right);$$

* **Forma Geral**: $$\min_{\beta,\, \sigma}\sum_{i=1}^n\left[\rho\left(\frac{Y_i-\mathbf{x}_i'\beta}{\sigma}\right)+\log\sigma\right].$$

Quando $\rho(\cdot)$ é diferenciável, as soluções das duas formas são dadas por:

$$\sum_{i=1}^n\mathbf{x}_i\Psi\left(Y_i-\mathbf{x}_i'\beta\right)=0\quad \text{e}\quad \sum_{i=1}^n\mathbf{x}_i\Psi\left(\frac{Y_i-\mathbf{x}_i'\beta}{\sigma}\right)=0.$$
---
class: animated, slideInRight

### M - Estimadores

#### Alguns exemplos de funções de perda ([Implementadas no R](https://cran.r-project.org/web/packages/robustbase/vignettes/psi_functions.pdf))

* Para $\rho(x)=x^2$, temos os estimadores de MQO;

* Para $\rho(x)=|x|$, temos os estimadores de mínimos absolutos;

* Para $\rho(x)=x^2\mathbb{I}_{|x|\le k}+(2k|x|-k^2)\mathbb{I}_{|x|>k}(x)$, temos 
os estimadores de Huber;

* Para $\rho(x)=\left(1-\left(1-\left(\frac{x}{k}\right)^2\right)^3\right)\mathbb{I}_{|x|\le k}(x)+\mathbb{I}_{|x|> k}(x)$, temos os estimadores bisquare de Tukey;

* Para 

$$\rho(x)=\begin{cases} \frac12x^2/C, & |x|<a;\\ \left(\frac12a^2+a(|x|-a)\right)/C, & a< |x|\le b; \\ \frac{a}{2}\left(2b-a+(|x|-b)\left(1+\frac{r-|x|}{r-b}\right)\right)/C, & b<|x|\le r;\\ 1, & r<|x|\end{cases}$$ 
temos os estimadores de Hampel.

---
class: animated, lightSpeedIn
# Referências

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(myBib, .opts = list(check.entries = FALSE))
```

---
class: animated, hide-logo, bounceInDown
## Política de proteção aos direitos autorais

> <span style="color:grey">O conteúdo disponível consiste em material protegido pela legislação brasileira, sendo certo que, por ser
o detentor dos direitos sobre o conteúdo disponível na plataforma, o **LECON** e o **NEAEST** detém direito
exclusivo de usar, fruir e dispor de sua obra, conforme Artigo 5<sup>o</sup>, inciso XXVII, da Constituição Federal
e os Artigos 7<sup>o</sup> e 28<sup>o</sup>, da Lei 9.610/98.
A divulgação e/ou veiculação do conteúdo em sites diferentes à plataforma e sem a devida autorização do
**LECON** e o **NEAEST**, pode configurar violação de direito autoral, nos termos da Lei 9.610/98, inclusive podendo
caracterizar conduta criminosa, conforme Artigo 184<sup>o</sup>, §1<sup>o</sup> a 3<sup>o</sup>, do Código Penal.
É considerada como contrafação a reprodução não autorizada, integral ou parcial, de todo e qualquer
conteúdo disponível na plataforma.</span>

.pull-left[
```{r, out.width='50%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/logo_lecon.png")
```
]
.pull-right[
```{r, out.width='50%', fig.align='center', fig.cap='',echo=FALSE}
knitr::include_graphics("images/logo_neaest.png")
```
]
<br></br>
.center[
[https://lecon.ufes.br](https://lecon.ufes.br/) &emsp; &emsp;  &emsp; &emsp; [https://analytics.ufes.br](https://analytics.ufes.br)
]

<font size="2"><span style="color:grey">Material elaborado pela equipe LECON/NEAEST: 
Alessandro J. Q. Sarnaglia, Bartolomeu Zamprogno, Fabio A. Fajardo, Luciana G. de Godoi 
e Nátaly A. Jiménez.</span></font>
